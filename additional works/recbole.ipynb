{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e115300-d808-479e-aa77-710ff457a32d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from recbole.quick_start import run_recbole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "67587f67-cdde-4cad-8007-a5c938f3da02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BaseDataset(object):\n",
    "    def __init__(self, input_path, output_path):\n",
    "        super(BaseDataset, self).__init__()\n",
    "\n",
    "        self.dataset_name = ''\n",
    "        self.input_path = input_path\n",
    "        self.output_path = output_path\n",
    "        self.check_output_path()\n",
    "\n",
    "        # input file\n",
    "        self.inter_file = os.path.join(self.input_path, 'inters.dat')\n",
    "        self.item_file = os.path.join(self.input_path, 'items.dat')\n",
    "        self.user_file = os.path.join(self.input_path, 'users.dat')\n",
    "        self.sep = '\\t'\n",
    "\n",
    "        # output file\n",
    "        self.output_inter_file, self.output_item_file, self.output_user_file = self.get_output_files()\n",
    "\n",
    "        # selected feature fields\n",
    "        self.inter_fields = {}\n",
    "        self.item_fields = {}\n",
    "        self.user_fields = {}\n",
    "\n",
    "    def check_output_path(self):\n",
    "        if not os.path.isdir(self.output_path):\n",
    "            os.makedirs(self.output_path)\n",
    "\n",
    "    def get_output_files(self):\n",
    "        output_inter_file = os.path.join(self.output_path, self.dataset_name + '.inter')\n",
    "        output_item_file = os.path.join(self.output_path, self.dataset_name + '.item')\n",
    "        output_user_file = os.path.join(self.output_path, self.dataset_name + '.user')\n",
    "        return output_inter_file, output_item_file, output_user_file\n",
    "\n",
    "    def load_inter_data(self) -> pd.DataFrame():\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def load_item_data(self) -> pd.DataFrame():\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def load_user_data(self) -> pd.DataFrame():\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def convert_inter(self):\n",
    "        try:\n",
    "            input_inter_data = self.load_inter_data()\n",
    "            self.convert(input_inter_data, self.inter_fields, self.output_inter_file)\n",
    "        except NotImplementedError:\n",
    "            print('This dataset can\\'t be converted to inter file\\n')\n",
    "\n",
    "    def convert_item(self):\n",
    "        try:\n",
    "            input_item_data = self.load_item_data()\n",
    "            self.convert(input_item_data, self.item_fields, self.output_item_file)\n",
    "        except NotImplementedError:\n",
    "            print('This dataset can\\'t be converted to item file\\n')\n",
    "\n",
    "    def convert_user(self):\n",
    "        try:\n",
    "            input_user_data = self.load_user_data()\n",
    "            self.convert(input_user_data, self.user_fields, self.output_user_file)\n",
    "        except NotImplementedError:\n",
    "            print('This dataset can\\'t be converted to user file\\n')\n",
    "\n",
    "    @staticmethod\n",
    "    def convert(input_data, selected_fields, output_file):\n",
    "        output_data = pd.DataFrame()\n",
    "        for column in selected_fields:\n",
    "            output_data[column] = input_data.iloc[:, column]\n",
    "        with open(output_file, 'w') as fp:\n",
    "            fp.write('\\t'.join([selected_fields[column] for column in output_data.columns]) + '\\n')\n",
    "            for i in tqdm(range(output_data.shape[0])):\n",
    "                fp.write('\\t'.join([str(output_data.iloc[i, j])\n",
    "                                    for j in range(output_data.shape[1])]) + '\\n')\n",
    "\n",
    "    def parse_json(self, data_path):\n",
    "        with open(data_path, 'rb') as g:\n",
    "            for l in g:\n",
    "                yield eval(l)\n",
    "\n",
    "    def getDF(self, data_path):\n",
    "        i = 0\n",
    "        df = {}\n",
    "        for d in self.parse_json(data_path):\n",
    "            df[i] = d\n",
    "            i += 1\n",
    "        data = pd.DataFrame.from_dict(df, orient='index')\n",
    "        \n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b0132f6-471e-4cec-a4ca-4aba0f203d44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BRDataset(BaseDataset):\n",
    "    def __init__(self, input_path, output_path):\n",
    "        super(BRDataset, self).__init__(input_path, output_path)\n",
    "        self.dataset_name = \"br\"\n",
    "\n",
    "        self.inter_file = os.path.join(self.input_path, \"train_ratings.csv\")\n",
    "        self.item_file = os.path.join(self.input_path, \"books.csv\")\n",
    "        self.user_file = os.path.join(self.input_path, \"users.csv\")\n",
    "\n",
    "        self.sep = \",\"\n",
    "\n",
    "        # output_path\n",
    "        output_files = self.get_output_files()\n",
    "        self.output_inter_file = output_files[0]\n",
    "        self.output_item_file = output_files[1]\n",
    "        self.output_user_file = output_files[2]\n",
    "\n",
    "        # selected feature fields\n",
    "        self.inter_fields = {\n",
    "            0: \"user_id:token\",\n",
    "            1: \"isbn:token\",\n",
    "            2: \"rating:float\"\n",
    "        }\n",
    "\n",
    "        self.user_fields = {\n",
    "            0: \"user_id:token\",\n",
    "            1: \"location:token_seq\",\n",
    "            2: \"age:token\"\n",
    "        }\n",
    "        \n",
    "        self.item_fields = {\n",
    "            0: \"isbn:token\",\n",
    "            1: \"book_title:token_seq\",\n",
    "            2: \"book_author:token_seq\",\n",
    "            3: \"year_of_publication:token\",\n",
    "            4: \"publisher:token\",\n",
    "            5: \"language:token\",\n",
    "            6: \"category:token_seq\",\n",
    "            7: \"summary:token_seq\"\n",
    "        }\n",
    "\n",
    "    def load_inter_data(self):\n",
    "        df = pd.read_csv(self.inter_file,\n",
    "            dtype={\"user_id\": \"object\", \"isbn\": \"object\", \"rating\": \"float\"}\n",
    "           )\n",
    "        # approx. 1 month + 2 weeks\n",
    "        df = df[-len(df)*3//48:].reset_index(drop=True)\n",
    "        # Further downsampling to avoid OOM\n",
    "        uus = df[\"user_id\"].unique()\n",
    "        sampled_users = np.random.choice(uus, len(uus)//6)\n",
    "        df = df.query('user_id in @sampled_users')\n",
    "        return df\n",
    "\n",
    "    def load_user_data(self):\n",
    "        return pd.read_csv(self.user_file,\n",
    "                           dtype={\"user_id\": \"object\", \"location\": \"object\", \"age\": pd.Int64Dtype()},\n",
    "                           delimiter=self.sep,\n",
    "                           engine=\"python\")\n",
    "    \n",
    "    def load_item_data(self):\n",
    "        return pd.read_csv(self.item_file,\n",
    "                           dtype={\"isbn\": \"object\", \"book_title\": \"object\", \"book_author\": \"object\", \"year_of_publication\": pd.Int64Dtype(), \"publisher\": \"object\", \"img_url\": \"object\", \"language\": \"object\", \"category\": \"object\", \"summary\": \"object\", \"img_path\": \"object\"},\n",
    "                           delimiter=self.sep,\n",
    "                           engine=\"python\").drop([\"img_url\", \"img_path\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "82d8f74d-56c6-47be-9ff2-730a5fd28f90",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2784/2784 [00:00<00:00, 12259.68it/s]\n",
      "100%|██████████| 68092/68092 [00:06<00:00, 10902.00it/s]\n",
      "100%|██████████| 149570/149570 [00:33<00:00, 4410.96it/s]\n"
     ]
    }
   ],
   "source": [
    "brds = BRDataset(\"../data\", \"./br\")\n",
    "brds.convert_inter()\n",
    "brds.convert_user()\n",
    "brds.convert_item()\n",
    "del brds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f5b36d8d-454a-4ba8-bf4d-83b41a5682a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BRTestDataset(BaseDataset):\n",
    "    def __init__(self, input_path, output_path):\n",
    "        super(BRTestDataset, self).__init__(input_path, output_path)\n",
    "        self.dataset_name = \"br_test\"\n",
    "\n",
    "        self.inter_file = os.path.join(self.input_path, \"test_ratings.csv\")\n",
    "\n",
    "        self.sep = \",\"\n",
    "\n",
    "        # output_path\n",
    "        output_files = self.get_output_files()\n",
    "        self.output_inter_file = output_files[0]\n",
    "\n",
    "        # selected feature fields\n",
    "        self.inter_fields = {\n",
    "            0: \"user_id:token\",\n",
    "            1: \"isbn:token\",\n",
    "            2: \"rating:float\"\n",
    "        }\n",
    "\n",
    "    def load_inter_data(self):\n",
    "        df = pd.read_csv(self.inter_file,\n",
    "            dtype={\"user_id\": \"object\", \"isbn\": \"object\", \"rating\": \"float\"}\n",
    "           )\n",
    "        # approx. 1 month + 2 weeks\n",
    "        df = df[-len(df)*3//48:].reset_index(drop=True)\n",
    "        # Further downsampling to avoid OOM\n",
    "        uus = df[\"user_id\"].unique()\n",
    "        sampled_users = np.random.choice(uus, len(uus)//6)\n",
    "        df = df.query('user_id in @sampled_users')\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7096ebda-32e3-40d2-a1e5-52c2c9524dbe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 698/698 [00:00<00:00, 13406.65it/s]\n"
     ]
    }
   ],
   "source": [
    "brdsTest = BRTestDataset(\"../data\", \"./br\")\n",
    "brdsTest.convert_inter()\n",
    "del brdsTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff354782-eec0-486b-80ab-e8256dbfd31e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cfg_str = \"\"\"\n",
    "data_path: ./\n",
    "dataset: br\n",
    "field_separator: \"\\\\t\"\n",
    "USER_ID_FIELD: user_id\n",
    "ITEM_ID_FIELD: isbn\n",
    "RATING_FIELD: rating\n",
    "TIME_FIELD: ~\n",
    "LABEL_FIELD: rating\n",
    "show_progress: false\n",
    "\n",
    "load_col:\n",
    "    inter: [user_id, isbn, rating]\n",
    "    user: [user_id, location, age]\n",
    "    item: [isbn, book_title, book_author, year_of_publication, publisher, language, category, summary]\n",
    "\n",
    "epochs: 5\n",
    "learning_rate: 0.01\n",
    "user_inter_num_interval: \"[0,inf)\"\n",
    "item_inter_num_interval: \"[0,inf)\"\n",
    "filter_inter_by_user_or_item: false\n",
    "neg_sampling:\n",
    "    uniform: 1\n",
    "eval_args:\n",
    "    split: {'RS': [6, 2, 2]}\n",
    "    group_by: None\n",
    "    mode: labeled\n",
    "metrics: ['RMSE']\n",
    "valid_metric: RMSE\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "with open(\"br/config.yaml\", \"w\") as f:\n",
    "    f.write(cfg_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f900c12-c24f-46c3-90e7-41ed24f3b972",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run(model_name):\n",
    "    if model_name in [\n",
    "        \"MultiVAE\",\n",
    "        \"MultiDAE\",\n",
    "        \"MacridVAE\",\n",
    "        \"RecVAE\",\n",
    "        \"GRU4Rec\",\n",
    "        \"NARM\",\n",
    "        \"STAMP\",\n",
    "        \"NextItNet\",\n",
    "        \"TransRec\",\n",
    "        \"SASRec\",\n",
    "        \"BERT4Rec\",\n",
    "        \"SRGNN\",\n",
    "        \"GCSAN\",\n",
    "        \"GRU4RecF\",\n",
    "        \"FOSSIL\",\n",
    "        \"SHAN\",\n",
    "        \"RepeatNet\",\n",
    "        \"HRM\",\n",
    "        \"NPE\",\n",
    "    ]:\n",
    "        parameter_dict = {\n",
    "            \"neg_sampling\": None\n",
    "        }\n",
    "        return run_recbole(\n",
    "            model=model_name,\n",
    "            dataset='br',\n",
    "            config_file_list=['br/config.yaml'],\n",
    "            config_dict=parameter_dict,\n",
    "        )\n",
    "    else:\n",
    "        return run_recbole(\n",
    "            model=model_name,\n",
    "            dataset='br',\n",
    "            config_file_list=['br/config.yaml'],\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b84616a-3388-4c04-baff-eb0f03358696",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_list = [\"FFM\"]\n",
    "# model_list = [\"Pop\", \"ItemKNN\", \"BPR\", \"NeuMF\", \"RecVAE\", \"LightGCN\"] # General\n",
    "# model_list += [\"FFM\", \"DeepFM\"] # Context-aware\n",
    "for model_name in model_list:\n",
    "    print(f\"running {model_name}...\")\n",
    "    start = time.time()\n",
    "    result = run(model_name)\n",
    "    t = time.time() - start\n",
    "    print(f\"It took {t/60:.2f} mins\")\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812bb267-50b3-43ac-9bdf-fa6f4a74c9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = [\"Pop\", \"ItemKNN\", \"BPR\", \"NeuMF\", \"RecVAE\", \"LightGCN\"] # General\n",
    "model_list += [\"FFM\", \"DeepFM\"] # Context-aware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c96df9f-2fd0-457f-adfb-cc864f4e7ac7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from recbole.config.configurator import Config\n",
    "from recbole.data.utils import create_dataset, data_preparation\n",
    "from recbole.utils import get_model, get_trainer\n",
    "\n",
    "def objective_function(config_dict=None, config_file_list=None):\n",
    "\n",
    "    config = Config(config_dict=config_dict, config_file_list=config_file_list)\n",
    "    dataset = create_dataset(config)\n",
    "    train_data, valid_data, test_data = data_preparation(config, dataset)\n",
    "    model_name = config['model']\n",
    "    model = get_model(model_name)(config, train_data._dataset).to(config['device'])\n",
    "    trainer = get_trainer(config['MODEL_TYPE'], config['model'])(config, model)\n",
    "    best_valid_score, best_valid_result = trainer.fit(train_data, valid_data, verbose=False)\n",
    "    test_result = trainer.evaluate(test_data)\n",
    "\n",
    "    return {\n",
    "        'model': model_name,\n",
    "        'best_valid_score': best_valid_score,\n",
    "        'valid_score_bigger': config['valid_metric_bigger'],\n",
    "        'best_valid_result': best_valid_result,\n",
    "        'test_result': test_result\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c688b0e0-1bd2-4623-80d9-c7c7dc0b031a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-04-17 02:38:05</td></tr>\n",
       "<tr><td>Running for: </td><td>00:43:00.09        </td></tr>\n",
       "<tr><td>Memory:      </td><td>6.6/88.5 GiB       </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=0<br>Bracket: Iter 90.000: None | Iter 30.000: None | Iter 10.000: None<br>Resources requested: 0/8 CPUs, 0/1 GPUs, 0.0/46.12 GiB heap, 0.0/9.31 GiB objects (0.0/1.0 accelerator_type:V100)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                    </th><th>status    </th><th>loc             </th><th style=\"text-align: right;\">  epoch</th><th style=\"text-align: right;\">  learning_rate</th><th>model  </th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  best_valid_score</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>objective_function_dfed1_00000</td><td>TERMINATED</td><td>172.17.0.2:57053</td><td style=\"text-align: right;\">     25</td><td style=\"text-align: right;\">    1.24804e-05</td><td>FM     </td><td style=\"text-align: right;\">               256</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1039.16 </td><td style=\"text-align: right;\">            6.6896</td></tr>\n",
       "<tr><td>objective_function_dfed1_00001</td><td>TERMINATED</td><td>172.17.0.2:57125</td><td style=\"text-align: right;\">     76</td><td style=\"text-align: right;\">    0.0755485  </td><td>FM     </td><td style=\"text-align: right;\">               512</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1049.27 </td><td style=\"text-align: right;\">            6.47  </td></tr>\n",
       "<tr><td>objective_function_dfed1_00002</td><td>TERMINATED</td><td>172.17.0.2:57127</td><td style=\"text-align: right;\">     74</td><td style=\"text-align: right;\">    0.0868598  </td><td>FM     </td><td style=\"text-align: right;\">              1024</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1047.44 </td><td style=\"text-align: right;\">            6.494 </td></tr>\n",
       "<tr><td>objective_function_dfed1_00003</td><td>TERMINATED</td><td>172.17.0.2:57129</td><td style=\"text-align: right;\">     55</td><td style=\"text-align: right;\">    3.55554e-05</td><td>FM     </td><td style=\"text-align: right;\">              2048</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1041.41 </td><td style=\"text-align: right;\">            6.7383</td></tr>\n",
       "<tr><td>objective_function_dfed1_00004</td><td>TERMINATED</td><td>172.17.0.2:57135</td><td style=\"text-align: right;\">     96</td><td style=\"text-align: right;\">    2.01359e-05</td><td>FM     </td><td style=\"text-align: right;\">               256</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1050.56 </td><td style=\"text-align: right;\">            6.6912</td></tr>\n",
       "<tr><td>objective_function_dfed1_00005</td><td>TERMINATED</td><td>172.17.0.2:57137</td><td style=\"text-align: right;\">     14</td><td style=\"text-align: right;\">    0.00741768 </td><td>FM     </td><td style=\"text-align: right;\">               512</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1049.32 </td><td style=\"text-align: right;\">            6.4524</td></tr>\n",
       "<tr><td>objective_function_dfed1_00006</td><td>TERMINATED</td><td>172.17.0.2:57139</td><td style=\"text-align: right;\">     79</td><td style=\"text-align: right;\">    0.0406584  </td><td>FM     </td><td style=\"text-align: right;\">              1024</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1049.5  </td><td style=\"text-align: right;\">            6.5004</td></tr>\n",
       "<tr><td>objective_function_dfed1_00007</td><td>TERMINATED</td><td>172.17.0.2:57143</td><td style=\"text-align: right;\">     89</td><td style=\"text-align: right;\">    0.00397239 </td><td>FM     </td><td style=\"text-align: right;\">              2048</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1036.38 </td><td style=\"text-align: right;\">            6.3967</td></tr>\n",
       "<tr><td>objective_function_dfed1_00008</td><td>TERMINATED</td><td>172.17.0.2:57053</td><td style=\"text-align: right;\">     12</td><td style=\"text-align: right;\">    0.00199372 </td><td>FM     </td><td style=\"text-align: right;\">               256</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1022.77 </td><td style=\"text-align: right;\">            6.3275</td></tr>\n",
       "<tr><td>objective_function_dfed1_00009</td><td>TERMINATED</td><td>172.17.0.2:57143</td><td style=\"text-align: right;\">     13</td><td style=\"text-align: right;\">    0.00440251 </td><td>FM     </td><td style=\"text-align: right;\">               512</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1020.59 </td><td style=\"text-align: right;\">            6.5127</td></tr>\n",
       "<tr><td>objective_function_dfed1_00010</td><td>TERMINATED</td><td>172.17.0.2:57129</td><td style=\"text-align: right;\">     77</td><td style=\"text-align: right;\">    4.39978e-05</td><td>FM     </td><td style=\"text-align: right;\">              1024</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1028.92 </td><td style=\"text-align: right;\">            6.7474</td></tr>\n",
       "<tr><td>objective_function_dfed1_00011</td><td>TERMINATED</td><td>172.17.0.2:57127</td><td style=\"text-align: right;\">     28</td><td style=\"text-align: right;\">    0.00956243 </td><td>FM     </td><td style=\"text-align: right;\">              2048</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1032.08 </td><td style=\"text-align: right;\">            6.3102</td></tr>\n",
       "<tr><td>objective_function_dfed1_00012</td><td>TERMINATED</td><td>172.17.0.2:57125</td><td style=\"text-align: right;\">     42</td><td style=\"text-align: right;\">    0.0776739  </td><td>FM     </td><td style=\"text-align: right;\">               256</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1038.02 </td><td style=\"text-align: right;\">            6.3841</td></tr>\n",
       "<tr><td>objective_function_dfed1_00013</td><td>TERMINATED</td><td>172.17.0.2:57137</td><td style=\"text-align: right;\">     62</td><td style=\"text-align: right;\">    0.000408569</td><td>FM     </td><td style=\"text-align: right;\">               512</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1037.27 </td><td style=\"text-align: right;\">            6.5196</td></tr>\n",
       "<tr><td>objective_function_dfed1_00014</td><td>TERMINATED</td><td>172.17.0.2:57139</td><td style=\"text-align: right;\">     52</td><td style=\"text-align: right;\">    0.00044184 </td><td>FM     </td><td style=\"text-align: right;\">              1024</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1036.26 </td><td style=\"text-align: right;\">            6.4943</td></tr>\n",
       "<tr><td>objective_function_dfed1_00015</td><td>TERMINATED</td><td>172.17.0.2:57135</td><td style=\"text-align: right;\">     17</td><td style=\"text-align: right;\">    1.1354e-05 </td><td>FM     </td><td style=\"text-align: right;\">              2048</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1034.18 </td><td style=\"text-align: right;\">            6.8296</td></tr>\n",
       "<tr><td>objective_function_dfed1_00016</td><td>TERMINATED</td><td>172.17.0.2:57143</td><td style=\"text-align: right;\">     37</td><td style=\"text-align: right;\">    0.00851273 </td><td>FM     </td><td style=\"text-align: right;\">               256</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         505.1  </td><td style=\"text-align: right;\">            6.4374</td></tr>\n",
       "<tr><td>objective_function_dfed1_00017</td><td>TERMINATED</td><td>172.17.0.2:57053</td><td style=\"text-align: right;\">     30</td><td style=\"text-align: right;\">    0.00636459 </td><td>FM     </td><td style=\"text-align: right;\">               512</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         498.178</td><td style=\"text-align: right;\">            6.273 </td></tr>\n",
       "<tr><td>objective_function_dfed1_00018</td><td>TERMINATED</td><td>172.17.0.2:57129</td><td style=\"text-align: right;\">     91</td><td style=\"text-align: right;\">    8.87514e-05</td><td>FM     </td><td style=\"text-align: right;\">              1024</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         498.846</td><td style=\"text-align: right;\">            6.5542</td></tr>\n",
       "<tr><td>objective_function_dfed1_00019</td><td>TERMINATED</td><td>172.17.0.2:57127</td><td style=\"text-align: right;\">     52</td><td style=\"text-align: right;\">    0.0817775  </td><td>FM     </td><td style=\"text-align: right;\">              2048</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         492.334</td><td style=\"text-align: right;\">            6.4486</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-17 02:38:05,813\tINFO tune.py:798 -- Total run time: 2580.13 seconds (2580.08 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params:  {'model': 'FM', 'epoch': 30, 'train_batch_size': 512, 'learning_rate': 0.006364591701150409}\n",
      "best result:  {'model': 'FM', 'best_valid_score': 6.273, 'valid_score_bigger': False, 'best_valid_result': OrderedDict([('rmse', 6.273)]), 'test_result': OrderedDict([('rmse', 6.5666)]), 'time_this_iter_s': 498.17821502685547, 'done': True, 'timesteps_total': None, 'episodes_total': None, 'training_iteration': 1, 'trial_id': 'dfed1_00017', 'experiment_id': '6c184032fc8249c396bd9badb3060271', 'date': '2023-04-17_02-37-49', 'timestamp': 1681699069, 'time_total_s': 498.17821502685547, 'pid': 57053, 'hostname': 'cf68c92cecb9', 'node_ip': '172.17.0.2', 'config': {'model': 'FM', 'epoch': 30, 'train_batch_size': 512, 'learning_rate': 0.006364591701150409}, 'time_since_restore': 498.17821502685547, 'timesteps_since_restore': 0, 'iterations_since_restore': 1, 'warmup_time': 0.003553628921508789, 'experiment_tag': '17_epoch=30,learning_rate=0.0064,model=FM,train_batch_size=512'}\n"
     ]
    }
   ],
   "source": [
    "from ray import tune\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "\n",
    "asha_scheduler = ASHAScheduler(\n",
    "    time_attr='training_iteration',\n",
    "    metric='best_valid_result/rmse',\n",
    "    mode='min',\n",
    "    max_t=100,\n",
    "    grace_period=10,\n",
    "    reduction_factor=3,\n",
    "    brackets=1,\n",
    ")\n",
    "\n",
    "config = {\n",
    "    \"model\": tune.grid_search([\"FM\"]),\n",
    "    \"epochs\": tune.randint(10, 100),\n",
    "    \"train_batch_size\": tune.grid_search([256, 512, 1024, 2048]),\n",
    "    \"learning_rate\": tune.loguniform(1e-5, 1e-1)\n",
    "}\n",
    "\n",
    "result = tune.run(\n",
    "    tune.with_parameters(objective_function, config_file_list=['/opt/ml/recbole/br/config.yaml']),\n",
    "    config=config,\n",
    "    num_samples=5,\n",
    "    log_to_file='log',\n",
    "    scheduler=asha_scheduler,\n",
    "    local_dir='result',\n",
    "    verbose=1\n",
    ")\n",
    "best_trial = result.get_best_trial('best_valid_result/rmse', 'min')\n",
    "print(\"best params: \",best_trial.config)\n",
    "print(\"best result: \",best_trial.last_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6fc37c6-c059-4e72-b2ce-6927755be6f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17 Apr 02:57    INFO  ['/opt/conda/envs/bc_recbole/lib/python3.8/site-packages/ipykernel_launcher.py', '-f', '/opt/ml/.local/share/jupyter/runtime/kernel-a88d0c04-6357-4a6c-a845-f7de34815b66.json']\n",
      "17 Apr 02:57    INFO  \n",
      "General Hyper Parameters:\n",
      "gpu_id = 0\n",
      "use_gpu = True\n",
      "seed = 2020\n",
      "state = INFO\n",
      "reproducibility = True\n",
      "data_path = /opt/ml/recbole/br\n",
      "checkpoint_dir = saved\n",
      "show_progress = False\n",
      "save_dataset = False\n",
      "dataset_save_path = None\n",
      "save_dataloaders = False\n",
      "dataloaders_save_path = None\n",
      "log_wandb = False\n",
      "\n",
      "Training Hyper Parameters:\n",
      "epochs = 30\n",
      "train_batch_size = 512\n",
      "learner = adam\n",
      "learning_rate = 0.006364591701150409\n",
      "train_neg_sample_args = {'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}\n",
      "eval_step = 1\n",
      "stopping_step = 10\n",
      "clip_grad_norm = None\n",
      "weight_decay = 0.0\n",
      "loss_decimal_place = 10\n",
      "\n",
      "Evaluation Hyper Parameters:\n",
      "eval_args = {'split': {'RS': [6, 2, 2]}, 'group_by': 'None', 'mode': 'labeled', 'order': 'RO'}\n",
      "repeatable = False\n",
      "metrics = ['RMSE']\n",
      "topk = [10]\n",
      "valid_metric = RMSE\n",
      "valid_metric_bigger = False\n",
      "eval_batch_size = 4096\n",
      "metric_decimal_place = 4\n",
      "\n",
      "Dataset Hyper Parameters:\n",
      "field_separator = \t\n",
      "seq_separator =  \n",
      "USER_ID_FIELD = user_id\n",
      "ITEM_ID_FIELD = isbn\n",
      "RATING_FIELD = rating\n",
      "TIME_FIELD = timestamp\n",
      "seq_len = None\n",
      "LABEL_FIELD = rating\n",
      "threshold = None\n",
      "NEG_PREFIX = neg_\n",
      "load_col = {'inter': ['user_id', 'isbn', 'rating'], 'user': ['user_id', 'location', 'age'], 'item': ['isbn', 'book_title', 'book_author', 'year_of_publication', 'publisher', 'language', 'category', 'summary']}\n",
      "unload_col = None\n",
      "unused_col = None\n",
      "additional_feat_suffix = None\n",
      "rm_dup_inter = None\n",
      "val_interval = None\n",
      "filter_inter_by_user_or_item = False\n",
      "user_inter_num_interval = [0,inf)\n",
      "item_inter_num_interval = [0,inf)\n",
      "alias_of_user_id = None\n",
      "alias_of_item_id = None\n",
      "alias_of_entity_id = None\n",
      "alias_of_relation_id = None\n",
      "preload_weight = None\n",
      "normalize_field = None\n",
      "normalize_all = None\n",
      "ITEM_LIST_LENGTH_FIELD = item_length\n",
      "LIST_SUFFIX = _list\n",
      "MAX_ITEM_LIST_LENGTH = 50\n",
      "POSITION_FIELD = position_id\n",
      "HEAD_ENTITY_ID_FIELD = head_id\n",
      "TAIL_ENTITY_ID_FIELD = tail_id\n",
      "RELATION_ID_FIELD = relation_id\n",
      "ENTITY_ID_FIELD = entity_id\n",
      "benchmark_filename = None\n",
      "\n",
      "Other Hyper Parameters: \n",
      "worker = 0\n",
      "wandb_project = recbole\n",
      "shuffle = True\n",
      "require_pow = False\n",
      "enable_amp = False\n",
      "enable_scaler = False\n",
      "transform = None\n",
      "embedding_size = 10\n",
      "numerical_features = []\n",
      "discretization = None\n",
      "kg_reverse_r = False\n",
      "entity_kg_num_interval = [0,inf)\n",
      "relation_kg_num_interval = [0,inf)\n",
      "MODEL_TYPE = ModelType.CONTEXT\n",
      "MODEL_INPUT_TYPE = InputType.POINTWISE\n",
      "eval_type = EvaluatorType.VALUE\n",
      "single_spec = True\n",
      "local_rank = 0\n",
      "device = cuda\n",
      "eval_neg_sample_args = {'distribution': 'none', 'sample_num': 'none'}\n",
      "\n",
      "\n",
      "17 Apr 02:57    INFO  br\n",
      "The number of users: 68093\n",
      "Average actions of users: 3.0933333333333333\n",
      "The number of items: 303135\n",
      "Average actions of items: 1.006871609403255\n",
      "The number of inters: 2784\n",
      "The sparsity of the dataset: 99.99998651252416%\n",
      "Remain Fields: ['user_id', 'isbn', 'rating', 'location', 'age', 'book_title', 'book_author', 'year_of_publication', 'publisher', 'language', 'category', 'summary']\n",
      "17 Apr 02:57    INFO  [Training]: train_batch_size = [512] train_neg_sample_args: [{'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}]\n",
      "17 Apr 02:57    INFO  [Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'RS': [6, 2, 2]}, 'group_by': 'None', 'mode': 'labeled', 'order': 'RO'}]\n",
      "17 Apr 02:57    INFO  FM(\n",
      "  (token_embedding_table): FMEmbedding(\n",
      "    (embedding): Embedding(383015, 10)\n",
      "  )\n",
      "  (token_seq_embedding_table): ModuleList(\n",
      "    (0): Embedding(13270, 10)\n",
      "    (1): Embedding(107202, 10)\n",
      "    (2): Embedding(37777, 10)\n",
      "    (3): Embedding(5482, 10)\n",
      "    (4): Embedding(91877, 10)\n",
      "  )\n",
      "  (first_order_linear): FMFirstOrderLinear(\n",
      "    (token_embedding_table): FMEmbedding(\n",
      "      (embedding): Embedding(383015, 1)\n",
      "    )\n",
      "    (token_seq_embedding_table): ModuleList(\n",
      "      (0): Embedding(13270, 1)\n",
      "      (1): Embedding(107202, 1)\n",
      "      (2): Embedding(37777, 1)\n",
      "      (3): Embedding(5482, 1)\n",
      "      (4): Embedding(91877, 1)\n",
      "    )\n",
      "  )\n",
      "  (fm): BaseFactorizationMachine()\n",
      "  (sigmoid): Sigmoid()\n",
      "  (loss): BCEWithLogitsLoss()\n",
      ")\n",
      "Trainable parameters: 7024854\n",
      "17 Apr 02:57    INFO  FLOPs: 1298.0\n",
      "17 Apr 02:57    INFO  epoch 0 training [time: 0.09s, train loss: -1.4821886830]\n",
      "17 Apr 02:57    INFO  epoch 0 evaluating [time: 0.02s, valid_score: 6.752600]\n",
      "17 Apr 02:57    INFO  valid result: \n",
      "rmse : 6.7526\n",
      "17 Apr 02:57    INFO  Saving current: saved/FM-Apr-17-2023_02-57-45.pth\n",
      "17 Apr 02:57    INFO  epoch 1 training [time: 0.09s, train loss: -18.6914873123]\n",
      "17 Apr 02:57    INFO  epoch 1 evaluating [time: 0.02s, valid_score: 6.638300]\n",
      "17 Apr 02:57    INFO  valid result: \n",
      "rmse : 6.6383\n",
      "17 Apr 02:57    INFO  Saving current: saved/FM-Apr-17-2023_02-57-45.pth\n",
      "17 Apr 02:57    INFO  epoch 2 training [time: 0.09s, train loss: -41.2883076668]\n",
      "17 Apr 02:57    INFO  epoch 2 evaluating [time: 0.02s, valid_score: 6.534300]\n",
      "17 Apr 02:57    INFO  valid result: \n",
      "rmse : 6.5343\n",
      "17 Apr 02:57    INFO  Saving current: saved/FM-Apr-17-2023_02-57-45.pth\n",
      "17 Apr 02:57    INFO  epoch 3 training [time: 0.09s, train loss: -71.1463165283]\n",
      "17 Apr 02:57    INFO  epoch 3 evaluating [time: 0.02s, valid_score: 6.461400]\n",
      "17 Apr 02:57    INFO  valid result: \n",
      "rmse : 6.4614\n",
      "17 Apr 02:57    INFO  Saving current: saved/FM-Apr-17-2023_02-57-45.pth\n",
      "17 Apr 02:57    INFO  epoch 4 training [time: 0.08s, train loss: -111.9921607971]\n",
      "17 Apr 02:57    INFO  epoch 4 evaluating [time: 0.02s, valid_score: 6.421600]\n",
      "17 Apr 02:57    INFO  valid result: \n",
      "rmse : 6.4216\n",
      "17 Apr 02:57    INFO  Saving current: saved/FM-Apr-17-2023_02-57-45.pth\n",
      "17 Apr 02:57    INFO  epoch 5 training [time: 0.08s, train loss: -160.1967086792]\n",
      "17 Apr 02:57    INFO  epoch 5 evaluating [time: 0.02s, valid_score: 6.403600]\n",
      "17 Apr 02:57    INFO  valid result: \n",
      "rmse : 6.4036\n",
      "17 Apr 02:57    INFO  Saving current: saved/FM-Apr-17-2023_02-57-45.pth\n",
      "17 Apr 02:57    INFO  epoch 6 training [time: 0.05s, train loss: -222.0335006714]\n",
      "17 Apr 02:57    INFO  epoch 6 evaluating [time: 0.02s, valid_score: 6.396800]\n",
      "17 Apr 02:57    INFO  valid result: \n",
      "rmse : 6.3968\n",
      "17 Apr 02:57    INFO  Saving current: saved/FM-Apr-17-2023_02-57-45.pth\n",
      "17 Apr 02:57    INFO  epoch 7 training [time: 0.08s, train loss: -299.6128463745]\n",
      "17 Apr 02:57    INFO  epoch 7 evaluating [time: 0.02s, valid_score: 6.394400]\n",
      "17 Apr 02:57    INFO  valid result: \n",
      "rmse : 6.3944\n",
      "17 Apr 02:57    INFO  Saving current: saved/FM-Apr-17-2023_02-57-45.pth\n",
      "17 Apr 02:57    INFO  epoch 8 training [time: 0.08s, train loss: -385.2041091919]\n",
      "17 Apr 02:57    INFO  epoch 8 evaluating [time: 0.02s, valid_score: 6.393700]\n",
      "17 Apr 02:57    INFO  valid result: \n",
      "rmse : 6.3937\n",
      "17 Apr 02:57    INFO  Saving current: saved/FM-Apr-17-2023_02-57-45.pth\n",
      "17 Apr 02:57    INFO  epoch 9 training [time: 0.08s, train loss: -500.8076019287]\n",
      "17 Apr 02:57    INFO  epoch 9 evaluating [time: 0.02s, valid_score: 6.393500]\n",
      "17 Apr 02:57    INFO  valid result: \n",
      "rmse : 6.3935\n",
      "17 Apr 02:57    INFO  Saving current: saved/FM-Apr-17-2023_02-57-45.pth\n",
      "17 Apr 02:57    INFO  epoch 10 training [time: 0.08s, train loss: -625.1093292236]\n",
      "17 Apr 02:57    INFO  epoch 10 evaluating [time: 0.02s, valid_score: 6.393400]\n",
      "17 Apr 02:57    INFO  valid result: \n",
      "rmse : 6.3934\n",
      "17 Apr 02:57    INFO  Saving current: saved/FM-Apr-17-2023_02-57-45.pth\n",
      "17 Apr 02:57    INFO  epoch 11 training [time: 0.08s, train loss: -767.6001281738]\n",
      "17 Apr 02:57    INFO  epoch 11 evaluating [time: 0.02s, valid_score: 6.393400]\n",
      "17 Apr 02:57    INFO  valid result: \n",
      "rmse : 6.3934\n",
      "17 Apr 02:57    INFO  Saving current: saved/FM-Apr-17-2023_02-57-45.pth\n",
      "17 Apr 02:57    INFO  epoch 12 training [time: 0.08s, train loss: -936.7811889648]\n",
      "17 Apr 02:57    INFO  epoch 12 evaluating [time: 0.02s, valid_score: 6.393400]\n",
      "17 Apr 02:57    INFO  valid result: \n",
      "rmse : 6.3934\n",
      "17 Apr 02:57    INFO  Saving current: saved/FM-Apr-17-2023_02-57-45.pth\n",
      "17 Apr 02:57    INFO  epoch 13 training [time: 0.08s, train loss: -1092.0058288574]\n",
      "17 Apr 02:57    INFO  epoch 13 evaluating [time: 0.02s, valid_score: 6.393400]\n",
      "17 Apr 02:57    INFO  valid result: \n",
      "rmse : 6.3934\n",
      "17 Apr 02:57    INFO  Saving current: saved/FM-Apr-17-2023_02-57-45.pth\n",
      "17 Apr 02:57    INFO  epoch 14 training [time: 0.09s, train loss: -1318.2820129395]\n",
      "17 Apr 02:57    INFO  epoch 14 evaluating [time: 0.02s, valid_score: 6.393400]\n",
      "17 Apr 02:57    INFO  valid result: \n",
      "rmse : 6.3934\n",
      "17 Apr 02:57    INFO  Saving current: saved/FM-Apr-17-2023_02-57-45.pth\n",
      "17 Apr 02:57    INFO  epoch 15 training [time: 0.09s, train loss: -1529.4758605957]\n",
      "17 Apr 02:57    INFO  epoch 15 evaluating [time: 0.02s, valid_score: 6.393400]\n",
      "17 Apr 02:57    INFO  valid result: \n",
      "rmse : 6.3934\n",
      "17 Apr 02:57    INFO  Saving current: saved/FM-Apr-17-2023_02-57-45.pth\n",
      "17 Apr 02:57    INFO  epoch 16 training [time: 0.08s, train loss: -1795.3392639160]\n",
      "17 Apr 02:57    INFO  epoch 16 evaluating [time: 0.02s, valid_score: 6.393400]\n",
      "17 Apr 02:57    INFO  valid result: \n",
      "rmse : 6.3934\n",
      "17 Apr 02:57    INFO  Saving current: saved/FM-Apr-17-2023_02-57-45.pth\n",
      "17 Apr 02:57    INFO  epoch 17 training [time: 0.08s, train loss: -2043.7859497070]\n",
      "17 Apr 02:57    INFO  epoch 17 evaluating [time: 0.02s, valid_score: 6.393400]\n",
      "17 Apr 02:57    INFO  valid result: \n",
      "rmse : 6.3934\n",
      "17 Apr 02:57    INFO  Saving current: saved/FM-Apr-17-2023_02-57-45.pth\n",
      "17 Apr 02:57    INFO  epoch 18 training [time: 0.08s, train loss: -2312.5261840820]\n",
      "17 Apr 02:57    INFO  epoch 18 evaluating [time: 0.02s, valid_score: 6.393400]\n",
      "17 Apr 02:57    INFO  valid result: \n",
      "rmse : 6.3934\n",
      "17 Apr 02:57    INFO  Saving current: saved/FM-Apr-17-2023_02-57-45.pth\n",
      "17 Apr 02:57    INFO  epoch 19 training [time: 0.08s, train loss: -2607.7299194336]\n",
      "17 Apr 02:57    INFO  epoch 19 evaluating [time: 0.02s, valid_score: 6.393400]\n",
      "17 Apr 02:57    INFO  valid result: \n",
      "rmse : 6.3934\n",
      "17 Apr 02:57    INFO  Saving current: saved/FM-Apr-17-2023_02-57-45.pth\n",
      "17 Apr 02:57    INFO  epoch 20 training [time: 0.08s, train loss: -2945.0277709961]\n",
      "17 Apr 02:57    INFO  epoch 20 evaluating [time: 0.02s, valid_score: 6.393400]\n",
      "17 Apr 02:57    INFO  valid result: \n",
      "rmse : 6.3934\n",
      "17 Apr 02:57    INFO  Saving current: saved/FM-Apr-17-2023_02-57-45.pth\n",
      "17 Apr 02:57    INFO  epoch 21 training [time: 0.08s, train loss: -3325.0538330078]\n",
      "17 Apr 02:57    INFO  epoch 21 evaluating [time: 0.02s, valid_score: 6.393400]\n",
      "17 Apr 02:57    INFO  valid result: \n",
      "rmse : 6.3934\n",
      "17 Apr 02:57    INFO  Saving current: saved/FM-Apr-17-2023_02-57-45.pth\n",
      "17 Apr 02:57    INFO  epoch 22 training [time: 0.08s, train loss: -3700.5189819336]\n",
      "17 Apr 02:57    INFO  epoch 22 evaluating [time: 0.02s, valid_score: 6.393400]\n",
      "17 Apr 02:57    INFO  valid result: \n",
      "rmse : 6.3934\n",
      "17 Apr 02:57    INFO  Saving current: saved/FM-Apr-17-2023_02-57-45.pth\n",
      "17 Apr 02:57    INFO  epoch 23 training [time: 0.09s, train loss: -4065.4912109375]\n",
      "17 Apr 02:57    INFO  epoch 23 evaluating [time: 0.02s, valid_score: 6.393400]\n",
      "17 Apr 02:57    INFO  valid result: \n",
      "rmse : 6.3934\n",
      "17 Apr 02:57    INFO  Saving current: saved/FM-Apr-17-2023_02-57-45.pth\n",
      "17 Apr 02:57    INFO  epoch 24 training [time: 0.09s, train loss: -4499.9959716797]\n",
      "17 Apr 02:57    INFO  epoch 24 evaluating [time: 0.02s, valid_score: 6.393400]\n",
      "17 Apr 02:57    INFO  valid result: \n",
      "rmse : 6.3934\n",
      "17 Apr 02:57    INFO  Saving current: saved/FM-Apr-17-2023_02-57-45.pth\n",
      "17 Apr 02:57    INFO  epoch 25 training [time: 0.08s, train loss: -4976.6972656250]\n",
      "17 Apr 02:57    INFO  epoch 25 evaluating [time: 0.02s, valid_score: 6.393400]\n",
      "17 Apr 02:57    INFO  valid result: \n",
      "rmse : 6.3934\n",
      "17 Apr 02:57    INFO  Saving current: saved/FM-Apr-17-2023_02-57-45.pth\n",
      "17 Apr 02:57    INFO  epoch 26 training [time: 0.08s, train loss: -5406.3554687500]\n",
      "17 Apr 02:57    INFO  epoch 26 evaluating [time: 0.02s, valid_score: 6.393400]\n",
      "17 Apr 02:57    INFO  valid result: \n",
      "rmse : 6.3934\n",
      "17 Apr 02:57    INFO  Saving current: saved/FM-Apr-17-2023_02-57-45.pth\n",
      "17 Apr 02:57    INFO  epoch 27 training [time: 0.08s, train loss: -5781.5797119141]\n",
      "17 Apr 02:57    INFO  epoch 27 evaluating [time: 0.02s, valid_score: 6.393400]\n",
      "17 Apr 02:57    INFO  valid result: \n",
      "rmse : 6.3934\n",
      "17 Apr 02:57    INFO  Saving current: saved/FM-Apr-17-2023_02-57-45.pth\n",
      "17 Apr 02:57    INFO  epoch 28 training [time: 0.04s, train loss: -6273.2502441406]\n",
      "17 Apr 02:57    INFO  epoch 28 evaluating [time: 0.02s, valid_score: 6.393400]\n",
      "17 Apr 02:57    INFO  valid result: \n",
      "rmse : 6.3934\n",
      "17 Apr 02:57    INFO  Saving current: saved/FM-Apr-17-2023_02-57-45.pth\n",
      "17 Apr 02:57    INFO  epoch 29 training [time: 0.08s, train loss: -6850.7752685547]\n",
      "17 Apr 02:57    INFO  epoch 29 evaluating [time: 0.02s, valid_score: 6.393400]\n",
      "17 Apr 02:57    INFO  valid result: \n",
      "rmse : 6.3934\n",
      "17 Apr 02:57    INFO  Saving current: saved/FM-Apr-17-2023_02-57-45.pth\n",
      "17 Apr 02:57    INFO  Loading model structure and parameters from saved/FM-Apr-17-2023_02-57-45.pth\n",
      "17 Apr 02:57    INFO  best valid : OrderedDict([('rmse', 6.3934)])\n",
      "17 Apr 02:57    INFO  test result: OrderedDict([('rmse', 6.4366)])\n"
     ]
    }
   ],
   "source": [
    "from recbole.quick_start import run_recbole\n",
    "\n",
    "result = run_recbole(\n",
    "    model='FM',\n",
    "    dataset='br',\n",
    "    config_file_list=['br/config.yaml'],\n",
    "    config_dict={'epochs': 30, 'train_batch_size': 512, 'learning_rate': 0.006364591701150409},\n",
    "    saved=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3efa8f8a-4517-4cce-aecb-108817ef61d0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17 Apr 02:58    INFO  \n",
      "General Hyper Parameters:\n",
      "gpu_id = 0\n",
      "use_gpu = True\n",
      "seed = 2020\n",
      "state = INFO\n",
      "reproducibility = True\n",
      "data_path = /opt/ml/recbole/br\n",
      "checkpoint_dir = saved\n",
      "show_progress = False\n",
      "save_dataset = False\n",
      "dataset_save_path = None\n",
      "save_dataloaders = False\n",
      "dataloaders_save_path = None\n",
      "log_wandb = False\n",
      "\n",
      "Training Hyper Parameters:\n",
      "epochs = 30\n",
      "train_batch_size = 512\n",
      "learner = adam\n",
      "learning_rate = 0.006364591701150409\n",
      "train_neg_sample_args = {'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}\n",
      "eval_step = 1\n",
      "stopping_step = 10\n",
      "clip_grad_norm = None\n",
      "weight_decay = 0.0\n",
      "loss_decimal_place = 10\n",
      "\n",
      "Evaluation Hyper Parameters:\n",
      "eval_args = {'split': {'RS': [6, 2, 2]}, 'group_by': 'None', 'mode': 'labeled', 'order': 'RO'}\n",
      "repeatable = False\n",
      "metrics = ['RMSE']\n",
      "topk = [10]\n",
      "valid_metric = RMSE\n",
      "valid_metric_bigger = False\n",
      "eval_batch_size = 4096\n",
      "metric_decimal_place = 4\n",
      "\n",
      "Dataset Hyper Parameters:\n",
      "field_separator = \t\n",
      "seq_separator =  \n",
      "USER_ID_FIELD = user_id\n",
      "ITEM_ID_FIELD = isbn\n",
      "RATING_FIELD = rating\n",
      "TIME_FIELD = timestamp\n",
      "seq_len = None\n",
      "LABEL_FIELD = rating\n",
      "threshold = None\n",
      "NEG_PREFIX = neg_\n",
      "load_col = {'inter': ['user_id', 'isbn', 'rating'], 'user': ['user_id', 'location', 'age'], 'item': ['isbn', 'book_title', 'book_author', 'year_of_publication', 'publisher', 'language', 'category', 'summary']}\n",
      "unload_col = None\n",
      "unused_col = None\n",
      "additional_feat_suffix = None\n",
      "rm_dup_inter = None\n",
      "val_interval = None\n",
      "filter_inter_by_user_or_item = False\n",
      "user_inter_num_interval = [0,inf)\n",
      "item_inter_num_interval = [0,inf)\n",
      "alias_of_user_id = None\n",
      "alias_of_item_id = None\n",
      "alias_of_entity_id = None\n",
      "alias_of_relation_id = None\n",
      "preload_weight = None\n",
      "normalize_field = None\n",
      "normalize_all = None\n",
      "ITEM_LIST_LENGTH_FIELD = item_length\n",
      "LIST_SUFFIX = _list\n",
      "MAX_ITEM_LIST_LENGTH = 50\n",
      "POSITION_FIELD = position_id\n",
      "HEAD_ENTITY_ID_FIELD = head_id\n",
      "TAIL_ENTITY_ID_FIELD = tail_id\n",
      "RELATION_ID_FIELD = relation_id\n",
      "ENTITY_ID_FIELD = entity_id\n",
      "benchmark_filename = None\n",
      "\n",
      "Other Hyper Parameters: \n",
      "worker = 0\n",
      "wandb_project = recbole\n",
      "shuffle = True\n",
      "require_pow = False\n",
      "enable_amp = False\n",
      "enable_scaler = False\n",
      "transform = None\n",
      "embedding_size = 10\n",
      "numerical_features = []\n",
      "discretization = None\n",
      "kg_reverse_r = False\n",
      "entity_kg_num_interval = [0,inf)\n",
      "relation_kg_num_interval = [0,inf)\n",
      "MODEL_TYPE = ModelType.CONTEXT\n",
      "MODEL_INPUT_TYPE = InputType.POINTWISE\n",
      "eval_type = EvaluatorType.VALUE\n",
      "single_spec = True\n",
      "local_rank = 0\n",
      "device = cuda\n",
      "eval_neg_sample_args = {'distribution': 'none', 'sample_num': 'none'}\n",
      "\n",
      "\n",
      "17 Apr 02:59    INFO  br\n",
      "The number of users: 68093\n",
      "Average actions of users: 3.0933333333333333\n",
      "The number of items: 303135\n",
      "Average actions of items: 1.006871609403255\n",
      "The number of inters: 2784\n",
      "The sparsity of the dataset: 99.99998651252416%\n",
      "Remain Fields: ['user_id', 'isbn', 'rating', 'location', 'age', 'book_title', 'book_author', 'year_of_publication', 'publisher', 'language', 'category', 'summary']\n",
      "17 Apr 02:59    INFO  [Training]: train_batch_size = [512] train_neg_sample_args: [{'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}]\n",
      "17 Apr 02:59    INFO  [Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'RS': [6, 2, 2]}, 'group_by': 'None', 'mode': 'labeled', 'order': 'RO'}]\n"
     ]
    }
   ],
   "source": [
    "config, model, dataset, train_data, valid_data, test_data = load_data_and_model(\n",
    "    model_file='saved/FM-Apr-17-2023_02-57-45.pth',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d9d8fcb5-b8d1-4ebf-be1f-a97cfa548af4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: '042518630X'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/envs/bc_recbole/lib/python3.8/site-packages/pandas/_libs/parsers.pyx:1129\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot cast array data from dtype('O') to dtype('int64') according to the rule 'safe'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m test \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m~/data/test_ratings.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43misbn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrating\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfloat\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m {columnName: torch\u001b[38;5;241m.\u001b[39mtensor(columnData\u001b[38;5;241m.\u001b[39mvalues) \u001b[38;5;28;01mfor\u001b[39;00m (columnName, columnData) \u001b[38;5;129;01min\u001b[39;00m test\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# input_inter = Interaction({columnName: columnData for (columnName, columnData) in stu_df.iteritems()})\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# input_inter = Interaction({\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m#         'item_length': torch.tensor([3, 2]),\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m#     })\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/bc_recbole/lib/python3.8/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/bc_recbole/lib/python3.8/site-packages/pandas/io/parsers/readers.py:583\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[0;32m--> 583\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/bc_recbole/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1704\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1697\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[1;32m   1698\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1699\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1700\u001b[0m     (\n\u001b[1;32m   1701\u001b[0m         index,\n\u001b[1;32m   1702\u001b[0m         columns,\n\u001b[1;32m   1703\u001b[0m         col_dict,\n\u001b[0;32m-> 1704\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[1;32m   1705\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[1;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1707\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1708\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/conda/envs/bc_recbole/lib/python3.8/site-packages/pandas/io/parsers/c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[0;32m--> 234\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[0;32m/opt/conda/envs/bc_recbole/lib/python3.8/site-packages/pandas/_libs/parsers.pyx:812\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/envs/bc_recbole/lib/python3.8/site-packages/pandas/_libs/parsers.pyx:889\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/envs/bc_recbole/lib/python3.8/site-packages/pandas/_libs/parsers.pyx:1034\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/envs/bc_recbole/lib/python3.8/site-packages/pandas/_libs/parsers.pyx:1135\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: '042518630X'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "test = pd.read_csv('~/data/test_ratings.csv', dtype={\"user_id\": int, \"isbn\": int, \"rating\": float})\n",
    "\n",
    "{columnName: torch.tensor(columnData.values) for (columnName, columnData) in test.items()}\n",
    "\n",
    "# input_inter = Interaction({columnName: columnData for (columnName, columnData) in stu_df.iteritems()})\n",
    "\n",
    "# input_inter = Interaction({\n",
    "#         'user_id': torch.tensor([1, 2]),\n",
    "#         'item_id_list': torch.tensor([[1, 2, 3, 0, 0],\n",
    "#                                       [4, 5, 0, 0, 0]]),\n",
    "#         'item_length': torch.tensor([3, 2]),\n",
    "#     })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "62e67077-0368-4492-887d-a919e604d304",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43muser_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool."
     ]
    }
   ],
   "source": [
    "torch.from_numpy(test['user_id'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "05ef0bfc-879a-45eb-a8c8-b9e71da37c2c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/br/br_test.inter\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/bc_recbole/lib/python3.8/site-packages/recbole/model/context_aware_recommender/fm.py:59\u001b[0m, in \u001b[0;36mFM.predict\u001b[0;34m(self, interaction)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, interaction):\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msigmoid(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43minteraction\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/opt/conda/envs/bc_recbole/lib/python3.8/site-packages/recbole/model/context_aware_recommender/fm.py:46\u001b[0m, in \u001b[0;36mFM.forward\u001b[0;34m(self, interaction)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, interaction):\n\u001b[0;32m---> 46\u001b[0m     fm_all_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat_embed_input_fields\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m        \u001b[49m\u001b[43minteraction\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# [batch_size, num_field, embed_dim]\u001b[39;00m\n\u001b[1;32m     49\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfirst_order_linear(interaction) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfm(fm_all_embeddings)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m y\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/envs/bc_recbole/lib/python3.8/site-packages/recbole/model/abstract_recommender.py:502\u001b[0m, in \u001b[0;36mContextRecommender.concat_embed_input_fields\u001b[0;34m(self, interaction)\u001b[0m\n\u001b[1;32m    501\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconcat_embed_input_fields\u001b[39m(\u001b[38;5;28mself\u001b[39m, interaction):\n\u001b[0;32m--> 502\u001b[0m     sparse_embedding, dense_embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_input_fields\u001b[49m\u001b[43m(\u001b[49m\u001b[43minteraction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    503\u001b[0m     all_embeddings \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    504\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sparse_embedding \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/envs/bc_recbole/lib/python3.8/site-packages/recbole/model/abstract_recommender.py:553\u001b[0m, in \u001b[0;36mContextRecommender.embed_input_fields\u001b[0;34m(self, interaction)\u001b[0m\n\u001b[1;32m    551\u001b[0m token_fields \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    552\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m field_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken_field_names:\n\u001b[0;32m--> 553\u001b[0m     token_fields\u001b[38;5;241m.\u001b[39mappend(\u001b[43minteraction\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfield_name\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m    554\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(token_fields) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    555\u001b[0m     token_fields \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(\n\u001b[1;32m    556\u001b[0m         token_fields, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    557\u001b[0m     )  \u001b[38;5;66;03m# [batch_size, num_token_field, 2]\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "input_inter = Interaction({\n",
    "        'user_id': torch.tensor([1, 2]),\n",
    "        'item_id_list': torch.tensor([[1, 2, 3, 0, 0],\n",
    "                                      [4, 5, 0, 0, 0]]),\n",
    "        'item_length': torch.tensor([3, 2]),\n",
    "    })\n",
    "\n",
    "model.predict('/br/br_test.inter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a5112e-69db-443a-88e3-ca8e7a1c7c90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ed35e8-a55e-4477-a465-fafc4ae594b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e485c589-7320-4b4c-93b7-8308cff7b4f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params:  {}\n",
      "best result:  {'model': 'FM', 'best_valid_score': 6.6316, 'valid_score_bigger': False, 'best_valid_result': OrderedDict([('rmse', 6.6316)]), 'test_result': OrderedDict([('rmse', 6.6092)]), 'time_this_iter_s': 35.80374240875244, 'done': True, 'timesteps_total': None, 'episodes_total': None, 'training_iteration': 1, 'trial_id': '1c16f_00002', 'experiment_id': '373b290cca96456fa965af312cfb0946', 'date': '2023-04-16_18-19-22', 'timestamp': 1681669162, 'time_total_s': 35.80374240875244, 'pid': 46048, 'hostname': 'cf68c92cecb9', 'node_ip': '172.17.0.2', 'config': {}, 'time_since_restore': 35.80374240875244, 'timesteps_since_restore': 0, 'iterations_since_restore': 1, 'warmup_time': 0.003397703170776367, 'experiment_tag': '2'}\n"
     ]
    }
   ],
   "source": [
    "from ray import tune\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "\n",
    "asha_scheduler = ASHAScheduler(\n",
    "    time_attr='training_iteration',\n",
    "    metric='best_valid_result/rmse',\n",
    "    mode='min',\n",
    "    max_t=100,\n",
    "    grace_period=10,\n",
    "    reduction_factor=3,\n",
    "    brackets=1,\n",
    ")\n",
    "\n",
    "config = {\n",
    "    \"model\": tune.grid_search([\"FM\"]),\n",
    "    \"epoch\": tune.randint(10, 100),\n",
    "    \"train_batch_size\": tune.grid_search([256, 512, 1024, 2048]),\n",
    "    \"learning_rate\": tune.loguniform(1e-5, 1e-1)\n",
    "}\n",
    "\n",
    "result = tune.run(\n",
    "    tune.with_parameters(objective_function, config_file_list=['/opt/ml/recbole/br/config.yaml']),\n",
    "    config=config,\n",
    "    num_samples=5,\n",
    "    log_to_file='log',\n",
    "    scheduler=asha_scheduler,\n",
    "    local_dir='result',\n",
    "    verbose=1\n",
    ")\n",
    "best_trial = result.get_best_trial('best_valid_result/rmse', 'min')\n",
    "print(\"best params: \",best_trial.config)\n",
    "print(\"best result: \",best_trial.last_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89d20dc-848d-4b20-ab92-8ea8e96e892d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "953e87e4-7b72-47b1-9ff2-f1871ca48561",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1;35mGeneral Hyper Parameters:\n",
       "\u001b[0m\u001b[1;36mgpu_id\u001b[0m =\u001b[1;33m 0\u001b[0m\n",
       "\u001b[1;36muse_gpu\u001b[0m =\u001b[1;33m True\u001b[0m\n",
       "\u001b[1;36mseed\u001b[0m =\u001b[1;33m 2020\u001b[0m\n",
       "\u001b[1;36mstate\u001b[0m =\u001b[1;33m INFO\u001b[0m\n",
       "\u001b[1;36mreproducibility\u001b[0m =\u001b[1;33m True\u001b[0m\n",
       "\u001b[1;36mdata_path\u001b[0m =\u001b[1;33m /opt/ml/recbole/br\u001b[0m\n",
       "\u001b[1;36mcheckpoint_dir\u001b[0m =\u001b[1;33m saved\u001b[0m\n",
       "\u001b[1;36mshow_progress\u001b[0m =\u001b[1;33m False\u001b[0m\n",
       "\u001b[1;36msave_dataset\u001b[0m =\u001b[1;33m False\u001b[0m\n",
       "\u001b[1;36mdataset_save_path\u001b[0m =\u001b[1;33m None\u001b[0m\n",
       "\u001b[1;36msave_dataloaders\u001b[0m =\u001b[1;33m False\u001b[0m\n",
       "\u001b[1;36mdataloaders_save_path\u001b[0m =\u001b[1;33m None\u001b[0m\n",
       "\u001b[1;36mlog_wandb\u001b[0m =\u001b[1;33m False\u001b[0m\n",
       "\n",
       "\u001b[1;35mTraining Hyper Parameters:\n",
       "\u001b[0m\u001b[1;36mepochs\u001b[0m =\u001b[1;33m 5\u001b[0m\n",
       "\u001b[1;36mtrain_batch_size\u001b[0m =\u001b[1;33m 2048\u001b[0m\n",
       "\u001b[1;36mlearner\u001b[0m =\u001b[1;33m adam\u001b[0m\n",
       "\u001b[1;36mlearning_rate\u001b[0m =\u001b[1;33m 0.01\u001b[0m\n",
       "\u001b[1;36mtrain_neg_sample_args\u001b[0m =\u001b[1;33m {'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}\u001b[0m\n",
       "\u001b[1;36meval_step\u001b[0m =\u001b[1;33m 1\u001b[0m\n",
       "\u001b[1;36mstopping_step\u001b[0m =\u001b[1;33m 10\u001b[0m\n",
       "\u001b[1;36mclip_grad_norm\u001b[0m =\u001b[1;33m None\u001b[0m\n",
       "\u001b[1;36mweight_decay\u001b[0m =\u001b[1;33m 0.0\u001b[0m\n",
       "\u001b[1;36mloss_decimal_place\u001b[0m =\u001b[1;33m 4\u001b[0m\n",
       "\n",
       "\u001b[1;35mEvaluation Hyper Parameters:\n",
       "\u001b[0m\u001b[1;36meval_args\u001b[0m =\u001b[1;33m {'split': {'RS': [6, 2, 2]}, 'group_by': 'None', 'mode': 'labeled', 'order': 'RO'}\u001b[0m\n",
       "\u001b[1;36mrepeatable\u001b[0m =\u001b[1;33m False\u001b[0m\n",
       "\u001b[1;36mmetrics\u001b[0m =\u001b[1;33m ['RMSE']\u001b[0m\n",
       "\u001b[1;36mtopk\u001b[0m =\u001b[1;33m [10]\u001b[0m\n",
       "\u001b[1;36mvalid_metric\u001b[0m =\u001b[1;33m RMSE\u001b[0m\n",
       "\u001b[1;36mvalid_metric_bigger\u001b[0m =\u001b[1;33m False\u001b[0m\n",
       "\u001b[1;36meval_batch_size\u001b[0m =\u001b[1;33m 4096\u001b[0m\n",
       "\u001b[1;36mmetric_decimal_place\u001b[0m =\u001b[1;33m 4\u001b[0m\n",
       "\n",
       "\u001b[1;35mDataset Hyper Parameters:\n",
       "\u001b[0m\u001b[1;36mfield_separator\u001b[0m =\u001b[1;33m \t\u001b[0m\n",
       "\u001b[1;36mseq_separator\u001b[0m =\u001b[1;33m  \u001b[0m\n",
       "\u001b[1;36mUSER_ID_FIELD\u001b[0m =\u001b[1;33m user_id\u001b[0m\n",
       "\u001b[1;36mITEM_ID_FIELD\u001b[0m =\u001b[1;33m isbn\u001b[0m\n",
       "\u001b[1;36mRATING_FIELD\u001b[0m =\u001b[1;33m rating\u001b[0m\n",
       "\u001b[1;36mTIME_FIELD\u001b[0m =\u001b[1;33m timestamp\u001b[0m\n",
       "\u001b[1;36mseq_len\u001b[0m =\u001b[1;33m None\u001b[0m\n",
       "\u001b[1;36mLABEL_FIELD\u001b[0m =\u001b[1;33m rating\u001b[0m\n",
       "\u001b[1;36mthreshold\u001b[0m =\u001b[1;33m None\u001b[0m\n",
       "\u001b[1;36mNEG_PREFIX\u001b[0m =\u001b[1;33m neg_\u001b[0m\n",
       "\u001b[1;36mload_col\u001b[0m =\u001b[1;33m {'inter': ['user_id', 'isbn', 'rating'], 'user': ['user_id', 'location', 'age'], 'item': ['isbn', 'book_title', 'book_author', 'year_of_publication', 'publisher', 'language', 'category', 'summary']}\u001b[0m\n",
       "\u001b[1;36munload_col\u001b[0m =\u001b[1;33m None\u001b[0m\n",
       "\u001b[1;36munused_col\u001b[0m =\u001b[1;33m None\u001b[0m\n",
       "\u001b[1;36madditional_feat_suffix\u001b[0m =\u001b[1;33m None\u001b[0m\n",
       "\u001b[1;36mrm_dup_inter\u001b[0m =\u001b[1;33m None\u001b[0m\n",
       "\u001b[1;36mval_interval\u001b[0m =\u001b[1;33m None\u001b[0m\n",
       "\u001b[1;36mfilter_inter_by_user_or_item\u001b[0m =\u001b[1;33m False\u001b[0m\n",
       "\u001b[1;36muser_inter_num_interval\u001b[0m =\u001b[1;33m [0,inf)\u001b[0m\n",
       "\u001b[1;36mitem_inter_num_interval\u001b[0m =\u001b[1;33m [0,inf)\u001b[0m\n",
       "\u001b[1;36malias_of_user_id\u001b[0m =\u001b[1;33m None\u001b[0m\n",
       "\u001b[1;36malias_of_item_id\u001b[0m =\u001b[1;33m None\u001b[0m\n",
       "\u001b[1;36malias_of_entity_id\u001b[0m =\u001b[1;33m None\u001b[0m\n",
       "\u001b[1;36malias_of_relation_id\u001b[0m =\u001b[1;33m None\u001b[0m\n",
       "\u001b[1;36mpreload_weight\u001b[0m =\u001b[1;33m None\u001b[0m\n",
       "\u001b[1;36mnormalize_field\u001b[0m =\u001b[1;33m None\u001b[0m\n",
       "\u001b[1;36mnormalize_all\u001b[0m =\u001b[1;33m None\u001b[0m\n",
       "\u001b[1;36mITEM_LIST_LENGTH_FIELD\u001b[0m =\u001b[1;33m item_length\u001b[0m\n",
       "\u001b[1;36mLIST_SUFFIX\u001b[0m =\u001b[1;33m _list\u001b[0m\n",
       "\u001b[1;36mMAX_ITEM_LIST_LENGTH\u001b[0m =\u001b[1;33m 50\u001b[0m\n",
       "\u001b[1;36mPOSITION_FIELD\u001b[0m =\u001b[1;33m position_id\u001b[0m\n",
       "\u001b[1;36mHEAD_ENTITY_ID_FIELD\u001b[0m =\u001b[1;33m head_id\u001b[0m\n",
       "\u001b[1;36mTAIL_ENTITY_ID_FIELD\u001b[0m =\u001b[1;33m tail_id\u001b[0m\n",
       "\u001b[1;36mRELATION_ID_FIELD\u001b[0m =\u001b[1;33m relation_id\u001b[0m\n",
       "\u001b[1;36mENTITY_ID_FIELD\u001b[0m =\u001b[1;33m entity_id\u001b[0m\n",
       "\u001b[1;36mbenchmark_filename\u001b[0m =\u001b[1;33m None\u001b[0m\n",
       "\n",
       "\u001b[1;35mOther Hyper Parameters: \n",
       "\u001b[0m\u001b[1;36mworker\u001b[0m = \u001b[1;33m0\u001b[0m\n",
       "\u001b[1;36mwandb_project\u001b[0m = \u001b[1;33mrecbole\u001b[0m\n",
       "\u001b[1;36mshuffle\u001b[0m = \u001b[1;33mTrue\u001b[0m\n",
       "\u001b[1;36mrequire_pow\u001b[0m = \u001b[1;33mFalse\u001b[0m\n",
       "\u001b[1;36menable_amp\u001b[0m = \u001b[1;33mFalse\u001b[0m\n",
       "\u001b[1;36menable_scaler\u001b[0m = \u001b[1;33mFalse\u001b[0m\n",
       "\u001b[1;36mtransform\u001b[0m = \u001b[1;33mNone\u001b[0m\n",
       "\u001b[1;36membedding_size\u001b[0m = \u001b[1;33m10\u001b[0m\n",
       "\u001b[1;36mnumerical_features\u001b[0m = \u001b[1;33m[]\u001b[0m\n",
       "\u001b[1;36mdiscretization\u001b[0m = \u001b[1;33mNone\u001b[0m\n",
       "\u001b[1;36mkg_reverse_r\u001b[0m = \u001b[1;33mFalse\u001b[0m\n",
       "\u001b[1;36mentity_kg_num_interval\u001b[0m = \u001b[1;33m[0,inf)\u001b[0m\n",
       "\u001b[1;36mrelation_kg_num_interval\u001b[0m = \u001b[1;33m[0,inf)\u001b[0m\n",
       "\u001b[1;36mMODEL_TYPE\u001b[0m = \u001b[1;33mModelType.CONTEXT\u001b[0m\n",
       "\u001b[1;36mMODEL_INPUT_TYPE\u001b[0m = \u001b[1;33mInputType.POINTWISE\u001b[0m\n",
       "\u001b[1;36meval_type\u001b[0m = \u001b[1;33mEvaluatorType.VALUE\u001b[0m\n",
       "\u001b[1;36msingle_spec\u001b[0m = \u001b[1;33mTrue\u001b[0m\n",
       "\u001b[1;36mlocal_rank\u001b[0m = \u001b[1;33m0\u001b[0m\n",
       "\u001b[1;36mdevice\u001b[0m = \u001b[1;33mcuda\u001b[0m\n",
       "\u001b[1;36meval_neg_sample_args\u001b[0m = \u001b[1;33m{'distribution': 'none', 'sample_num': 'none'}\u001b[0m\n"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Config(config_dict=None, config_file_list=['/opt/ml/recbole/br/config.yaml'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924bba4e-4248-4c62-9f19-8b6352b60849",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beec23f3-554c-48c4-9788-5051ae162100",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ray import tune\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "\n",
    "asha_scheduler = ASHAScheduler(\n",
    "    time_attr='training_iteration',\n",
    "    metric='best_valid_result/rmse',\n",
    "    mode='min',\n",
    "    max_t=100,\n",
    "    grace_period=10,\n",
    "    reduction_factor=3,\n",
    "    brackets=1,\n",
    ")\n",
    "\n",
    "config = {\n",
    "    \"learning_rate\": tune.grid_search([0.001, 0.01]),\n",
    "    \"momentum\": tune.grid_search([0.5, 0.9])\n",
    "}\n",
    "\n",
    "result = tune.run(\n",
    "    tune.with_parameters(objective_function, config_file_list=['/opt/ml/recbole/br/config.yaml']),\n",
    "    config=config,\n",
    "    num_samples=5,\n",
    "    log_to_file='log',\n",
    "    scheduler=asha_scheduler,\n",
    "    local_dir='result',\n",
    "    verbose=1\n",
    ")\n",
    "best_trial = result.get_best_trial('best_valid_result/rmse', 'min')\n",
    "print(\"best params: \",best_trial.config)\n",
    "print(\"best result: \",best_trial.last_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2f7cc2-d1be-4805-8e17-05ba04f33f77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bc_recbole",
   "language": "python",
   "name": "bc_recbole"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
